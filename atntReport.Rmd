---
title: "**Analysis to Predict Closing Stock Prices from Company AT&T**"
author: 
- Victor Yung
- Benson Ou-yang
- Ivan Cao

abstract:
  In our project, we are trying to determine if we are capable of developing a 
  suitable model using regression analysis that allows for trades in the market 
  to be fully automated. Mentioned under the data’s context on Kaggle, roughly 
  30% of the trades are already automated. We gathered the data from the company
   AT&T from the years 2013-2016 and added in the yearly fundamental data. 
   Furthermore, we used visual graphs to analyze the residuals to help identify 
   any underlying problems we came across when developing our model. By 
   data-splitting, we acquired a model that was capable of predicting the 
   closing prices roughly 69% of the time. The overall analysis of the model 
   helped us subset and distinguish the effectiveness of each regressor we 
   found to the response variable, however we were expecting our model to have 
   a higher percentage predicting closing stock price of AT&T.  

output: 
  bookdown::pdf_document2:
    extra_dependencies: "subfig"
    fig_caption: yes
    includes: 
      in_header: my_header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r global-options, include=FALSE}
knitr::opts_chunk$set(fig.height=3.5, fig.path='Figs/', fig.pos = "H",
                      echo=FALSE, warning=FALSE, message=FALSE)
```

```{r package-options, include=FALSE}
knitr::opts_knit$set(progress = TRUE, verbose = TRUE)
```

# Introduction

The telecommunication industry is growing inevitably, and it is highly dependent
on the rapid advancement of technology. The telecommunication industry is a key
element for businesses and individuals to collaborate from anywhere across the
world. As a result, there will be investment opportunities present, however it
is not risk free. In our analysis, we designate our efforts toward one of the
most well-known telecommunication companies around the world, AT&T. 


```{r, echo = FALSE,message= FALSE}
library(lubridate)
library(tidyverse)
library(faraway)
library(caret)
library(reshape2)
library(car)
```


```{r, echo = FALSE}
# securities is the dataset containing sector information 
securities = read.csv("securities.csv")

# fund contains yearly fundamental information about each company 
fund = read.csv("fundamentals.csv")

# psa contains adjusted prices of daily stock prices
psa = read.csv("prices-split-adjusted.csv")

# adjusted prices for company AT&T

tprices = psa[psa$symbol == "T",]

# reset indexes
row.names(tprices) = NULL
```


```{r,echo = FALSE}
# change date to datetime object
tprices$date = ymd(tprices$date)

# placeholder for column names in for loop
fundminus = select(fund,-c("X","Ticker.Symbol","Period.Ending","For.Year"))


# separate fund data corresponding to tprices only
ex = fund[fund$Ticker.Symbol == "T",]

# adding last years yearly info into present year
tprices$year = year(tprices$date)-1
tprices = tprices[tprices$year %in% unique(ex$For.Year),]

# for loops to add all columns of fund into tprices

for(j in unique(ex$For.Year)){
  for(k in names(fundminus)){
    tprices[tprices$year == j, k] = ex[ex$For.Year == j, k]
  }
}


tprices = select(tprices, c("close","volume","date", "year",
                            "Capital.Surplus","Gross.Margin","Liabilities"))

tprices$year = year(tprices$date)

```



```{r,echo = FALSE}
# adding a data point at the end 
added_obs = data.frame("2017-01-01", 30, 98323500, 9.1038e+10, 57, 1798000000)
names(added_obs) = c("date", "close", "volume", "Capital.Surplus", 
                     "Gross.Margin", "Liabilities")
added_obs$date = ymd(added_obs$date)
added_obs$year = year(added_obs$date)

row.names(tprices) = NULL
# the last row is the added observation
tprices = rbind(tprices, added_obs)


```

# Data Description

We are using three datasets: \verb|securities.csv|, \verb|fundamentals.csv|, and 
\verb|prices-split-adjusted.csv|.

\verb|Securities.csv| contains information on the stock companies such as the 
company's name and ticker symbol, the type of sector they are in, location of 
headquarters and others. 

\verb|Fundamentals.csv| contains information of yearly reports of fundamental 
information of each company such as \verb|total| \verb|revenue|, \verb|accounts| 
\verb|payable|, \verb|liabilities| and many more.

\verb|Prices-split-adjusted.csv| contains information of the stocks adjusted 
prices after splitting. The columns included are the \verb|date|, \verb|ticker| 
\verb|symbol|, \verb|close|, \verb|open|, \verb|low|, \verb|high|,and 
\verb|volume|.


```{r, echo = FALSE}
mdl = lm(close ~ volume + Capital.Surplus + Gross.Margin + Liabilities ,
         tprices)
```


For our linear regression model, we have selected to predict close prices of 
AT&T’s stock. Our regressor variables are volume from the 
\verb|prices-split-adjusted.csv| and \verb|capital surplus|, \verb|gross margin|,
and \verb|liabilities| from the \verb|fundamentals.csv|. See Equation 
\@ref(eq:mlr) 

\begin{equation}
  close = \beta_0 + \beta_1(volume) + \beta_2(Capital Surplus) + 
  \beta_3(Gross Margin) + \beta_4(Liabilities) + \epsilon (\#eq:mlr)
\end{equation}


Since the data from the \verb|fundamentals.csv| is annual, we merged the previous 
year's dataset with the following year's \verb|prices-split-adjusted.csv| data of 
AT&T to form the full dataset. For example, if the \verb|total| \verb|revenue| 
for 2013 is \$1,000,000 so we made a column for total revenue and made every row 
that is in 2014 to be \$1,000,000. We ran a nested for loop to apply this for all 
years and columns. \verb|Tprices| is the DataFrame with the columns of interest 
for our linear model. See Table \@ref(tab:names-tab).

```{r names-tab}

knitr::kable(names(tprices), format = "markdown", 
             caption = "Column Names of DataFrame Tprices", col.names = "Columns")
```


\verb|Close| corresponds to the price of the stock when the market closes on 
that day.

\verb|Volume| is the number of trades that occurred that day.

\verb|Date| is the date of the trading day.

\verb|Year| is the year of the trading day.

\verb|Capital.surplus| or share premium, most commonly refers to the surplus 
resulting after common stock is sold for more than its par value.

\verb|Gross.margin| is a company's net sales revenue minus its cost of goods 
sold. The higher the gross margin, the more capital a company retains on each 
dollar of sales, which it can then use to pay other costs or satisfy debt 
obligations.

\verb|Liabilities| are the debts and obligations of a company.


```{r c-plot,fig.cap="Daily Market Close Price of AT&T"}
ggplot(data = tprices , aes(x = date, y = close)) + geom_line() + 
    ggtitle("Market Close Price of AT&T Over the Years") + xlab("Time") + 
    ylab("Close Price($)") + 
    geom_point(aes(x = tprices[date == "2013-01-02", "date"], 
                   y = tprices[date == "2013-01-02", "close"]), color = "red") + 
    geom_point(aes(x = tprices[date == "2014-01-02", "date"], 
                   y = tprices[date == "2014-01-02", "close"]), color = "red") + 
    geom_point(aes(x = tprices[date == "2015-01-02", "date"], 
                   y = tprices[date == "2015-01-02", "close"]), color = "red") + 
    geom_point(aes(x = tprices[date == "2016-01-04", "date"], 
                   y = tprices[date == "2016-01-04", "close"]), color = "red")
```


Figure \@ref(fig:c-plot) represents the market closing price of the stock for 
AT&T over the span of 2013 to 2017. The red points on the line mark as an 
indication when the year begins. We notice that 2013 and 2014 closing prices 
both started around \$35. Around spring of 2013, the stock shot up to about 
\$39 which is the highest closing price until 2016. The stock drops to about 
\$32 in the beginning of the year and before 2015. In 2016, the stock was 
starting to rise and in mid 2016, the stock got a new record of about \$43.


```{r, echo = FALSE}
summary(tprices$close)
```

```{r,echo = FALSE, results='hide'}
head(sort(tprices$close, decreasing = FALSE))
```

In the five number summary of the close prices, the minimum is our added 
observation of \$30 . Without the added observation, the lowest is \$31.80. 
The max close price is \$43.47. The mean close price is \$35.77.


```{r v-plot, fig.cap="Daily Volume Traded of ATNT"}
ggplot(data = tprices, 
       aes(x = year, y = volume, group = year, fill = year)) + geom_boxplot() +
        ggtitle("Volume of Trades of AT&T Throughout the Years")

```

Figure \@ref(fig:v-plot) shows the volume traded each year. The mean volume 
traded yearly is roughly the same except for 2015. The dots on the boxplot 
represent the outliers from that given year. There are days where the stock 
is traded more often than usual which could be caused by good news, low stock 
prices, etc. On the other hand, there are also days where volume is lower than 
usual since the stock price is higher causing people who own the stock to hold 
or the price being too high that does not incentivize buyers, etc.

```{r,echo = FALSE}
print("Summary of Volume in 2013")
summary(tprices[tprices$year == 2013,"volume"])
print("Summary of Volume in 2014")
summary(tprices[tprices$year == 2014,"volume"])
print("Summary of Volume in 2015")
summary(tprices[tprices$year == 2015,"volume"])
print("Summary of Volume in 2016")
summary(tprices[tprices$year == 2016,"volume"])
```

```{r cs-plot,fig.cap="Capital Surplus of ATNT 2013-2016"}
# Capital surplus, or share premium, most commonly refers to the surplus 
# resulting after common stock is sold for more than its par value.

ggplot(data = tprices, aes(x = year, y = Capital.Surplus)) + geom_point() +
  labs(x = "Year", y = "Capital Surplus", 
         title = "Capital Surplus of AT&T Over the Years")
```

Figure \@ref(fig:cs-plot) shows the capital surplus of each year. It was rising 
up until 2016 where it dropped by significantly.

```{r l-plot, fig.cap="Liabilities of ATNT 2013-2016"}
# The debts and obligations of a company or an individual. Current liabilities 
# are debts due and payable within one year. Long-term liabilities are those 
# payable after one year.

ggplot(data = tprices, aes(x = year, y = Liabilities)) + geom_point() +
  labs(x = "Year", 
         title = "Liabilities of AT&T Over the Years")
```

Figure \@ref(fig:l-plot) shows the liabilities of each year. In 2013 and 2015, 
AT&T had the highest liabilities. In 2014, they had the lowest. In 2016, it was 
between the highest and lowest liabilities.

```{r gm-plot, fig.cap="Gross Margin of ATNT 2013-2016"}
# Gross margin is a company's net sales revenue minus its cost of goods sold 
# (COGS). ... The higher the gross margin, the more capital a company retains 
# on each dollar of sales, which it can then use to pay other costs or satisfy 
# debt obligations.

ggplot(data = tprices, aes(x = year, y = Gross.Margin)) + geom_point() +
  labs(x = "Year", y = "Gross Margin", 
         title = "Gross Margin of AT&T Over the Years")
```

Figure \@ref(fig:gm-plot) shows the gross margin of each year. From 2013 to 
2014, it rose up to the highest of 60. In 2015 it fell down to 55 and 2016 
dropped to 54.

```{r pp-plot, fig.cap = "Pairs Plot of Columns of Tprices",fig.height=3.25}
pairs(tprices)
```

Figure \@ref(fig:pp-plot) shows the columns plotted against each other. Since 
the columns from the fundamentals.csv is yearly data, when plotted against other
columns, they are shown as separate lines due to the values being the same daily 
for the year.

```{r h-map,fig.cap = "Correlation Between Variables", fig.width = 8, fig.height = 5}
# adapted from http://www.sthda.com/english/wiki/ggplot2-quick-correlation-
# matrix-heatmap-r-software-and-data-visualization

# gathered the columns we needed and made data frame into a matrix

tmat = as.matrix(select(tprices,-c("date","year")))

# get the correlation between the columns
tcor = round(cor(tmat),2)

# function to just get the upper triangle of values for heatmap
get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
}

# reorder the correlation matrix based on its correlation

reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}

tcor = reorder_cormat(tcor)

upper_tri = get_upper_tri(tcor)

# melt for plottable data

melted = melt(upper_tri,na.rm = TRUE)

# produces heat map

heatmap = ggplot(data = melted, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed() + geom_text(aes(Var2, Var1, label = value), color = "black", 
                           size = 4) +
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.5, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5)) + 
  ggtitle("Heatmap of Correlation Between Regressors")

print(heatmap)

```

Figure \@ref(fig:h-map) shows the correlation between each column.

# Methods

## Datasets

To begin, we chose to combine two of the four datasets offered, 
“Price-split-adjusted” (PSA) and “Fundamentals” (Fund). The PSA dataset accounts
for all stocks traded in the NYSE daily from 2010-2016 and the Fund dataset 
accounts for the 10-K filing from 2012-2016, an annual comprehensive report 
required by the U.S. Securities and Exchanges Commission (SEC). Since the dates
in the datasets varies from daily in PSA and annually in Fund, we attach the 
previous year’s filing of the 10-K report to help predict the next year over.

## Choosing Regressors

When first developing the model, we included open as one of the predictors for 
close. As a result, the correlation of our model increased to 99%, this is 
because if a stock were to open higher than the average, it is most likely 
going to close higher than the average. Also, if other predictors were to be 
added with open, the variance inflation factor will be increased to a level 
where there are clear violations of multicollinearity. In the end, we decided 
not to include open as part of our model because it is unrealistic to be able 
to predict the model with 99% accuracy.

```{r}
ogdf = psa[psa$symbol == "T",]

first_mdl = lm(close~open+low+high+volume, data = ogdf)

summary(first_mdl)
```

This is the summary of our first model.

```{r}
vif(first_mdl)
```

These are the variance inflation factors. \verb|Open|, \verb|low|, and 
\verb|high| have values vastly greater than 10, thus this model suffers from
severe multicollinearity.

## Subsetting Dataset

Since our datasets covers different years, we kept only the years that overlap 
in both datasets, 2013-2016. Lastly, we removed all companies other than our 
company of focus, AT&T. With 76 columns in \verb|fundamentals.csv| that were 
added into \verb|tprices| DataFrame, we ran into issues with fitting the model 
with all the columns. The error that came up was due to singularities with the
columns. The singularities are due to the fact that many of the variables are
dependent of each other. The model would fit up to four variables and the other 
coefficients would be NA. Due to this, we handpicked the variables 
\verb|Capital.Surplus|, \verb|Liabilities|, and \verb|Gross.Margins|. We
subsetted the DataFrame to just include \verb|close|, \verb|volume|, \verb|date|,
\verb|year|, \verb|year|, \verb|Capital.Surplus|, \verb|Gross.Margin|, and
\verb|Liabilities|. Table \@ref(tab:t-tab) presents the subsetted data. 

```{r t-tab}
knitr::kable(tprices[1:5,1:7], format="markdown", 
             caption = "First five rows of tprices DataFrame")
```


## Model Adequacy

```{r ma-plot, fig.cap='Model Adequacy Plots', fig.subcap=c('Residuals vs Fitted Plot','Normal QQ Plot','Scale-Location Plot','Residuals vs Leverage'),fig.height = 3.5, fig.ncol = 2,out.width = "50%"}

# Model Adequacy 
plot(mdl, which = 1)
plot(mdl, which = 2)
plot(mdl, which = 3)
plot(mdl, which = 5)
```

Checking model adequacy is an important step to measure the accuracy of the model. 
\textbf{The Residuals vs. Fitted values} in Figure \@ref(fig:ma-plot)(a) shows 
whether the residuals have a relationship with each other. Ideally, the points 
would be randomly scattered about zero with no patterns. In our plot, the spaces 
in between the four groups represent the four different years ranging from 
2013-2016. When observing the residuals vs fitted, it seems as though the points
are scattered randomly about zero, starting with a negative relationship into a 
more stable relationship as the plot moves from left to right. We also see that 
the scatter on the far right is more spread out which could point out to 
potential problems down the line.


The \textbf{normal Q-Q plot} in Figure \@ref(fig:ma-plot)(b) shows whether the 
errors are normally distributed. If the errors were normally distributed, 
points are expected to rest on the line with minimum gaps. Our plot has 
noticeable gaps on both ends labeling point 761 and 763 as potential outliers. 
The plot seems to be light tailed but nonetheless the plot is about normal due 
to the amount of observations.


The \textbf{scale-location plot} in Figure \@ref(fig:ma-plot)(c) shows whether the 
residuals are spread equally among the predictors and whether the assumption 
of constant variance is met. Ideally, the plot show has points scattered equally
horizontally. In our plot, we see that there are four groups of points, the 
first three groups (from left to right) seem to follow constant variance but the
points in the rightmost group have a wider spread compared to the previous 
three. The residuals in the plot do not meet constant variance assumption. 
Our plot points out point 761 and 763 as potential outliers.


The \textbf{residuals vs leverage plot} in Figure \@ref(fig:ma-plot)(d) points 
out the influential observations within our dataset. The dotted line represents 
the cook’s distance and any points that fall outside of the dotted red line 
signifies a highly influential point to the regression results. If we were to 
exclude these observations, our regression will change and improve. In our case,
no points fall outside of the cook’s distance, this may be due to the large 
number of observations included in the data. The plot did highlight point 65, 
396, and 1009 (our added point) as potential outliers.


```{r av-plot, fig.cap = "Added Variable Plot of Model"}
avPlots(mdl)
```

The Added Variable Plots in Figure \@ref(fig:av-plot) aim to compare each 
regressor against the response variable while controlling the presence of the 
other regressors. Since the variables in the fundamental dataset are presented 
annually and are merged with daily data, the variable-plot consists of grouping 
points. 


We also investigated the leverage and influential points. A leverage point is
when $h_{ii}$ > $2p/n$, where \verb|p| is the number of predictors and \verb|n|
is the number of rows of the dataset. $h_{ii}$ comes from the diagonal elements 
of the hat matrix(\@ref(eq:hat)):

\begin{equation}
  \boldsymbol{H} = \boldsymbol{X} (\boldsymbol{X}'\boldsymbol{X})^{-1}  
  \boldsymbol{X} (\#eq:hat)
\end{equation}

The high leverage points are sorted here. Data point 1009 is the one data point
that we added in. Measuring for leverage points caught this point.

```{r lev-tab}
# leverage point if hii > 2p/n

influ = influence(mdl) # measures leverage points
# head(sort(influ$hat, decreasing = TRUE))

# decreasing leverage points
sort(influ$hat[influ$hat>(2*4)/nrow(tprices)],decreasing = TRUE)

```



```{r}
# influential point if Di > 1

cooks = cooks.distance(mdl) # measures influential points
# head(sort(cooks,decreasing = TRUE))
# which(cooks > 1) # no influential points
```


```{r}
# remove leverage points and assess
rowindex = names(influ$hat[influ$hat>(2*4)/nrow(tprices)])
df = tprices

# for loop to make id column to reference row
for(i in 1:nrow(tprices)){
  df[i,"id"] = i
}

newdata = df[!(df$id %in% c(rowindex)),]
newdata = select(newdata,-"id")

no_lev_mdl = lm(close~volume + Capital.Surplus + Gross.Margin + Liabilities ,
         newdata)
```

```{r nolev-plot, fig.cap='Model Adequacy Plots', fig.subcap=c('Residuals vs Fitted Plot','Normal QQ Plot','Scale-Location Plot','Residuals vs Leverage'),fig.height = 3.5, fig.ncol = 2,out.width = "50%"}

# Model Adequacy 
plot(no_lev_mdl, which = 1)
plot(no_lev_mdl, which = 2)
plot(no_lev_mdl, which = 3)
plot(no_lev_mdl, which = 5)
```

By removing the leverage points, the model adequacy plots in Figure 
\@ref(fig:nolev-plot) improve as the grouping of the points are less evident 
in all plots. There seems to be less clustering of points without the leverage 
points and for the residuals vs leverage plot in Figure \@ref(fig:nolev-plot)(d), 
the data points looks more spread out.

```{r}
summary(no_lev_mdl)
```

By removing the leverage points, the $R^2$ improves from 0.6638 to 0.6832.

Here we checked the Variance Inflation Factor(\verb|VIF|),

```{r}
vif(mdl)
```

The \verb|VIF| for \verb|Capital.Surplus|, \verb|Gross.Margin|, and 
\verb|Liabilities| are pretty high but they are less than 10 so 
they are acceptable.

## Model Selection

By performing stepwise selection with our model, we discovered that our current 
model is the best for predicting closing stock price for AT&T therefore no 
variables need to be removed. See Equation \@ref(eq:mlr) above.

```{r}
step(no_lev_mdl)
```

## Model Validation

After assessing the model adequacy, we go on to validate our model to see if it 
can function properly and successfully for the intended user. To do this, 
we sampled 80% of the AT&T data to form the training dataset, leaving 20% to 
be the testing set. The model and results will be shown in the following section.

```{r}
set.seed(75392)

df = newdata

nsamp=ceiling(0.8*length(df$close))
training_samps=sample(c(1:length(df$close)),
                      nsamp)
training_samps=sort(training_samps)
train_data  <- df[training_samps, ]
test_data <-   df[-training_samps, ]


train.lm <- lm(close ~ volume + Capital.Surplus + Gross.Margin + Liabilities, 
               data = train_data)

preds <- predict(train.lm,test_data)
```


# Result

This is the summary of fitting a model on the training data.

```{r}
summary(train.lm)
```

This is the summary of the full model without the leverage points.

```{r}
summary(no_lev_mdl)
```

When comparing the coefficients and p values from the two models, the 
coefficients remain similar and the regressors that were previously found to be 
significant are still significant.


```{r pred-p, fig.cap = "Predicted Values Plotted with Actual Values With y=x Line"}
plot(test_data$close,preds, xlab = "Actual Close Price", 
     ylab = "Predicted Close Price", main = "Actual vs Predicted Close Price")
abline(c(0,1))
```

Figure \@ref(fig:pred-p) shows the relationship between predicted close price 
(y-axis) versus actual close price (x-axis). We notice that the fitted line 
provides a positive slope across the plot indicating that there is a positive 
linear relationship between the predicted and actual close price. In addition, 
the points are evenly scattered around the fitted line which is a sign of 
constant variance. However, the points do not rest directly on the line which 
means that our model is not capable of perfectly predicting closing price. 
Although the two points on the top left of the plot could be potential outliers, 
removing them will not make a significant difference in the overall pattern so 
we can leave it as is.


```{r info-tab}
R.sq = R2(preds, test_data$close)
RMSPE = RMSE(preds, test_data$close)
MAPE = MAE(preds, test_data$close)
NSE=RMSPE/sd(test_data$close)
# print(c(R.sq,RMSPE,MAPE,NSE))

info = data.frame("R2" = R.sq, "RMSPE" = RMSPE, "MAPE" = MAPE, "NSE" = NSE)

knitr::kable(info, format = "markdown", 
             caption = "Table containing $R^{2}_{Prediction}$, Root Mean Square 
             Prediction Error, Mean Absolute Prediction Error, 
             Normalized Standard Error")
```  

In Table \@ref(tab:info-tab), we generated the $R^{2}_{Prediction}$, Root Mean
Square Prediction Error, Mean Absolute Prediction Error and Normalized Standard
Error. After sampling 80% of the data, $R^{2}_{Prediction}$ uses the same 
regressors as the original model but uses the sampled data (train dataset) 
instead of the full data. By calling the summary using the predicted linear 
model, we can observe the correlation between regressors and response of the 
train dataset. The sampled data is capable of predicting the remaining 20% of 
the data 69% of the time.
  
The Root Mean Square Prediction Error (Equation \@ref(eq:RMSPE)) is the standard 
deviation of the residuals. It is a measure of how far the data points deviate 
from the regression line.
  
  
\begin{equation}
  \boldsymbol{RMSPE} = \sqrt{\frac{1}{\boldsymbol{n}}\sum_{i=1}^{n}
  (\boldsymbol{y_i} - \boldsymbol{\hat{y_i}})^2}
  (\#eq:RMSPE)
\end{equation}
  
  
The Mean Absolute Prediction Value measures the average magnitude of the data 
points that deviate from the fitted line. See Equation \@ref(eq:MAPE).
  
  
\begin{equation}
  \boldsymbol{MAPE} = \frac{1}{\boldsymbol{n}}\sum_{i=1}^{n}
  |\boldsymbol{y_i} - \boldsymbol{\hat{y_i}}|
  (\#eq:MAPE)
\end{equation}
  
  
The Normalized Standard Error(Equation \@ref(eq:NSE)) is the normalized Root Mean
Square Prediction Error. Normalizing it tells us if the Root Mean Square 
Prediction Error value is a low value or not. It tells us how much variability 
we have explained. For example, a value of 1 says the model explains none of the 
variability. 
  
  
\begin{equation}
  \boldsymbol{NSE} = \frac{\boldsymbol{RMSPE}}{\boldsymbol{\sigma_{test}}}
  (\#eq:NSE)
\end{equation}
  
  

```{r test-plot, fig.cap="Time Series Plot of Actual Close Price and Predicted Close Price"}
plot(test_data$date, test_data$close, type = 'l', 
     main = "AT&T Close Price Over Time", ylab = "Close Price" ,xlab = "Time")
lines(test_data$date, preds, col = "red")
legend(x = "bottomright",legend = c("Actual","Predicted"),pch = "___", 
       col = c("black","red"))
```

Figure \@ref(fig:test-plot) shows the overall pattern of close prices of AT&T 
stocks over years 2013 to 2016 with the one data point that we added for 2017. 
This plot gives a visual representation of the difference between the predicted 
closing price (labelled in red) versus the actual closing price (labelled in 
black).We see that our predicted prices are generally more stable than the 
actual prices meaning that there are some variations between what we predicted 
versus what the actual price of the closing stock is at a certain point in time. 
From the results we see our prediction is not 100% accurate but it does show that 
it is not completely off as it provides similar patterns to the actual closing 
price which the 0.69 from the R^2 prediction explains.Furthermore, we also 
notice a large shift in the pattern from the beginning to the end of 2016 where 
the closing price has been the highest since recent years. This is an indication 
that the value of the company has grown.


# Conclusion

In conclusion, our prediction model used 80% of the training data to predict the
testing data with 69% accuracy. Although this is not perfect, the 69% accuracy 
is tolerable considering that we only have 4 predictors to the model. 

Some of the limitations of the data presented in this case includes not being 
able to use the data prior to 2013 because the fundamental dataset lacked the 
years 2010-2012, not having more information on day to day stock activities that
can help better predict how volatile the stocks are, and how well the company’s 
did in the earnings report.

Listed below are some of the examples of better predictors of stock price 
excluding the ones already included in the dataset.

\begin{enumerate}
  \item	\verb|Price| \verb|to| \verb|Earnings| \verb|Ratio| – determines market 
value of stock compared to the company’s reported earnings.
  \item	\verb|Market| \verb|Capitalization| – refers to the total value of all the 
company’s shares in stock. Market capitalization is the total from (number of 
common shares * stock price).
  \item	\verb|Earnings| \verb|per| \verb|Share| – how much a company earns per 
share, higher EPS means stock has higher value than those in the same industry.
\end{enumerate}

By having quarterly information on the earnings reports of AT&T, the user of the
dataset would have been able to better predict how the stock would react in the 
following days after the earnings report is released. For context, if AT&T’s 
earning report were to beat the expectations, the stock would perform better on 
the following days. In conjunction with adding extra predictors listed above, 
the predictive power of the model would most likely increase.

Although the dataset on Kaggle highlights that roughly 30% of daily trades are 
performed by machine, the results of and the limitations of our study points 
towards the complexity of the stock market that must be considered to make an 
accurate forecast model. 




# Appendix

## URL: 
[Repository containing all files](https://github.com/bensonouyang/NYStocks)  

## Data Files: 
[fundamentals.csv](https://github.com/bensonouyang/NYStocks/blob/main/fundamentals.csv)  
[prices-split-adjusted.csv](https://github.com/bensonouyang/NYStocks/blob/main/prices-split-adjusted.csv)  
[securities.csv](https://github.com/bensonouyang/NYStocks/blob/main/securities.csv)  

## Raw Code:
[rawcode.Rmd](https://github.com/bensonouyang/NYStocks/blob/main/rawcode.Rmd)  

## Report:
[atntReport.Rmd](https://github.com/bensonouyang/NYStocks/blob/main/atntReport.Rmd)  
[atntReport.pdf](https://github.com/bensonouyang/NYStocks/blob/main/atntReport.pdf)  

## Text Files:
[README.md](https://github.com/bensonouyang/NYStocks/blob/main/README.md)  
[my_header.tex](https://github.com/bensonouyang/NYStocks/blob/main/my_header.tex)  

## Required Libraries:

\verb|lubridate|  
\verb|tidyverse|  
\verb|faraway|  
\verb|caret|  
\verb|reshape2|  
\verb|car|  
\verb|knitr|  
\verb|bookdown|

